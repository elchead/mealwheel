{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leaed\\anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/leaed/Documents/Techlabs/Mealwheeldata/\"\n",
    "raw_interactions = pd.read_csv(path + \"RAW_interactions.csv\", sep=\",\")\n",
    "raw_interactions = raw_interactions[[\"user_id\", \"recipe_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightFM will not use our IDs, but rather internal indices\n",
    "# It does this, because it needs consecutive non-negative integers (but the input could be anything)\n",
    "# Therefore, we need a mapping between our IDs and the internal indices\n",
    "# E.g. user_id = 38094 -> internal_user_id = 1, user_id = 1293707 -> internal_user_id = 2\n",
    "# Very well explained: https://making.lyst.com/lightfm/docs/examples/dataset.html?highlight=dataset\n",
    "#building-the-id-mappings\n",
    "\n",
    "# We can do this easily by using the Dataset class from the LightFM package\n",
    "dataset = Dataset()\n",
    "dataset.fit(users=raw_interactions[\"user_id\"], items=raw_interactions[\"recipe_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To have an easy way of converting input ids to internal ids, we define a mappings class\n",
    "class Mappings:\n",
    "    def __init__(self, dataset: Dataset) -> None:\n",
    "        \"\"\"\n",
    "        userid: user_id\n",
    "        row: internal user id\n",
    "        itemid: recipe_id\n",
    "        column: internal recipe id\n",
    "        \"\"\"\n",
    "        userid2row, _, itemid2col, _ = dataset.mapping()\n",
    "        self.userid2row = userid2row\n",
    "        self.itemid2col = itemid2col\n",
    "        # Invert dictionaries to get mapping in other direction\n",
    "        self.row2userid = {value: key for key, value in self.userid2row.items()}\n",
    "        self.col2itemid = {v: k for k, v in self.itemid2col.items()}\n",
    "        # Use like this: \n",
    "        # mappings = Mappings(dataset)\n",
    "        # mappings.userid2row[\"axfafe24\"]\n",
    "\n",
    "# And use it:\n",
    "mappings = Mappings(dataset)\n",
    "# Example. This returns the internal user id of user_id=38094\n",
    "mappings.userid2row[1293707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "class LightFMResizable(LightFM):\n",
    "    \"\"\"A LightFM that resizes the model to accomodate new users,\n",
    "    items, and features\"\"\"\n",
    "\n",
    "    def fit_partial(\n",
    "        self,\n",
    "        interactions,\n",
    "        user_features=None,\n",
    "        item_features=None,\n",
    "        sample_weight=None,\n",
    "        epochs=1,\n",
    "        num_threads=1,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        try:\n",
    "            self._check_initialized()\n",
    "            self._resize(interactions, user_features, item_features)\n",
    "        except ValueError:\n",
    "            # This is the first call so just fit without resizing\n",
    "            pass\n",
    "\n",
    "        super().fit_partial(\n",
    "            interactions,\n",
    "            user_features,\n",
    "            item_features,\n",
    "            sample_weight,\n",
    "            epochs,\n",
    "            num_threads,\n",
    "            verbose,\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _resize(self, interactions, user_features=None, item_features=None):\n",
    "        \"\"\"Resizes the model to accommodate new users/items/features\"\"\"\n",
    "\n",
    "        no_components = self.no_components\n",
    "        no_user_features, no_item_features = interactions.shape  # default\n",
    "\n",
    "        if hasattr(user_features, \"shape\"):\n",
    "            no_user_features = user_features.shape[-1]\n",
    "        if hasattr(item_features, \"shape\"):\n",
    "            no_item_features = item_features.shape[-1]\n",
    "\n",
    "        if (\n",
    "            no_user_features == self.user_embeddings.shape[0]\n",
    "            and no_item_features == self.item_embeddings.shape[0]\n",
    "        ):\n",
    "            return self\n",
    "\n",
    "        new_model = clone(self)\n",
    "        new_model._initialize(no_components, no_item_features, no_user_features)\n",
    "\n",
    "        # update all attributes from self._check_initialized\n",
    "        for attr in (\n",
    "            \"item_embeddings\",\n",
    "            \"item_embedding_gradients\",\n",
    "            \"item_embedding_momentum\",\n",
    "            \"item_biases\",\n",
    "            \"item_bias_gradients\",\n",
    "            \"item_bias_momentum\",\n",
    "            \"user_embeddings\",\n",
    "            \"user_embedding_gradients\",\n",
    "            \"user_embedding_momentum\",\n",
    "            \"user_biases\",\n",
    "            \"user_bias_gradients\",\n",
    "            \"user_bias_momentum\",\n",
    "        ):\n",
    "            # extend attribute matrices with new rows/cols from\n",
    "            # freshly initialized model with right shape\n",
    "            old_array = getattr(self, attr)\n",
    "            old_slice = [slice(None, i) for i in old_array.shape]\n",
    "            new_array = getattr(new_model, attr)\n",
    "            new_array[tuple(old_slice)] = old_array\n",
    "            setattr(self, attr, new_array)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we build the interaction matrix (a table with users as rows and recipes as columns, and a 1 in the cell if the user rated the recipe)\n",
    "interactions, _ = dataset.build_interactions(raw_interactions.to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could also add item_features (like the ratings)\n",
    "# https://making.lyst.com/lightfm/docs/examples/dataset.html?highlight=dataset#building-the-interactions-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can raw_datae model\n",
    "# This might take a few minutes\n",
    "model = LightFMResizable(loss=\"warp\", learning_rate=0.05, random_state=42)\n",
    "model.fit(interactions=interactions, epochs=100)\n",
    "\n",
    "# Save model to pickle file\n",
    "# filename = \"recommendation_model.pkl\"\n",
    "# with open(filename, 'wb') as file:  \n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from pickle file\n",
    "filename = \"recommendation_model.pkl\" \n",
    "with open(filename, 'rb') as file:  \n",
    "    model = pickle.load(file)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fit partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = pd.DataFrame({\n",
    "    \"user_id\":  [1,1,1,1,1],\n",
    "    \"recipe_id\":  [4065, 10123, 295797, 108524, 10045]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fit_partial(users=new_user[\"user_id\"], items=new_user[\"recipe_id\"])\n",
    "new_interactions, _ = dataset.build_interactions(new_user.to_records(index=False))\n",
    "\n",
    "# In production update your old model with new data.\n",
    "model.fit_partial(interactions=new_interactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "Get recommendations for one sample user and check if the recommendations make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0169863, -1.3943113, -1.1754183, ..., -2.5216193, -2.3398874,\n",
       "       -1.7851042], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the user for which predictions should be made\n",
    "user_id = 2001868099\n",
    "# Get the internal id (or: row) for this user\n",
    "user_row = mappings.userid2row[user_id]\n",
    "# Get the number of items in the dataset\n",
    "_, n_items = dataset.interactions_shape()\n",
    "# Get an array with all internal item ids\n",
    "item_columns = np.arange(n_items) # [0, 1, 2, ..., 231636]\n",
    "# Get the scores for each item (for our user)\n",
    "scores = model.predict(user_ids=user_row, item_ids=item_columns)\n",
    "# How to interpret:\n",
    "# score[0] = recommendation score for internal item id 0\n",
    "# score[1] = recommendation score for internal item id 1\n",
    "# ...\n",
    "# The item with the highest score is most likely to be a good recommendation\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(129280, 2.0713909),\n",
       " (12327, 2.0420403),\n",
       " (148330, 1.9232008),\n",
       " (170922, 1.9062672),\n",
       " (72090, 1.8858923),\n",
       " (174671, 1.859283),\n",
       " (61923, 1.8318424),\n",
       " (93563, 1.7970877),\n",
       " (136768, 1.778458),\n",
       " (161114, 1.7582388)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function that sorts the scores and returns the top_n elements\n",
    "def get_top_sorted(scores: np.ndarray, top_n):\n",
    "    \"\"\"\n",
    "    Get the top indices sorted descendingly from the scores list array.\n",
    "    Args:\n",
    "        scores: An array with scores.\n",
    "        top_n: The number of top scores to be returned.\n",
    "    Returns:\n",
    "        ScoringList: The first element of the tuple is the index where the score was\n",
    "                in the original array, the second element is the score itself.\n",
    "    \"\"\"\n",
    "    best_idxs = np.argpartition(scores, -top_n)[-top_n:]\n",
    "    return sorted(zip(best_idxs, scores[best_idxs]), key=lambda x: -x[1])\n",
    "\n",
    "# Example: Use fuction to return top 5 recommendations\n",
    "sorted_scores_top_10 = get_top_sorted(scores, 10)\n",
    "sorted_scores_top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>27208</td>\n",
       "      <td>2.071391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>97496</td>\n",
       "      <td>2.042040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>39087</td>\n",
       "      <td>1.923201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>32204</td>\n",
       "      <td>1.906267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>67256</td>\n",
       "      <td>1.885892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>89204</td>\n",
       "      <td>1.859283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>54257</td>\n",
       "      <td>1.831842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>80156</td>\n",
       "      <td>1.797088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>2886</td>\n",
       "      <td>1.778458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>15411</td>\n",
       "      <td>1.758239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  recipe_id     score\n",
       "0  2001868099      27208  2.071391\n",
       "1  2001868099      97496  2.042040\n",
       "2  2001868099      39087  1.923201\n",
       "3  2001868099      32204  1.906267\n",
       "4  2001868099      67256  1.885892\n",
       "5  2001868099      89204  1.859283\n",
       "6  2001868099      54257  1.831842\n",
       "7  2001868099      80156  1.797088\n",
       "8  2001868099       2886  1.778458\n",
       "9  2001868099      15411  1.758239"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add results to a DataFrame\n",
    "recommendations = pd.DataFrame(sorted_scores_top_10, columns=[\"internal_item_id\", \"score\"])\n",
    "# Add user_id\n",
    "recommendations[\"user_id\"] = user_id\n",
    "# Add recipe_id\n",
    "# Google something like \"python apply lambda\" to learn more about how this works\n",
    "recommendations[\"recipe_id\"] = recommendations[\"internal_item_id\"].apply(lambda x: mappings.col2itemid[x])\n",
    "# Drop internal_item_id and reorder other columns\n",
    "recommendations = recommendations[[\"user_id\", \"recipe_id\", \"score\"]]\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>score</th>\n",
       "      <th>recipe_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>27208</td>\n",
       "      <td>2.071391</td>\n",
       "      <td>to die for crock pot roast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>97496</td>\n",
       "      <td>2.042040</td>\n",
       "      <td>soft snickerdoodle cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>39087</td>\n",
       "      <td>1.923201</td>\n",
       "      <td>creamy cajun chicken pasta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>32204</td>\n",
       "      <td>1.906267</td>\n",
       "      <td>whatever floats your boat  brownies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>67256</td>\n",
       "      <td>1.885892</td>\n",
       "      <td>best ever banana cake with cream cheese frosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>89204</td>\n",
       "      <td>1.859283</td>\n",
       "      <td>crock pot chicken with black beans   cream cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>54257</td>\n",
       "      <td>1.831842</td>\n",
       "      <td>yes  virginia there is a great meatloaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>80156</td>\n",
       "      <td>1.797088</td>\n",
       "      <td>the most wonderful gingerbread cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>2886</td>\n",
       "      <td>1.778458</td>\n",
       "      <td>best banana bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>15411</td>\n",
       "      <td>1.758239</td>\n",
       "      <td>impossible peanut butter cookies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  recipe_id     score  \\\n",
       "0  2001868099      27208  2.071391   \n",
       "1  2001868099      97496  2.042040   \n",
       "2  2001868099      39087  1.923201   \n",
       "3  2001868099      32204  1.906267   \n",
       "4  2001868099      67256  1.885892   \n",
       "5  2001868099      89204  1.859283   \n",
       "6  2001868099      54257  1.831842   \n",
       "7  2001868099      80156  1.797088   \n",
       "8  2001868099       2886  1.778458   \n",
       "9  2001868099      15411  1.758239   \n",
       "\n",
       "                                         recipe_name  \n",
       "0                         to die for crock pot roast  \n",
       "1                         soft snickerdoodle cookies  \n",
       "2                         creamy cajun chicken pasta  \n",
       "3                whatever floats your boat  brownies  \n",
       "4   best ever banana cake with cream cheese frosting  \n",
       "5  crock pot chicken with black beans   cream cheese  \n",
       "6            yes  virginia there is a great meatloaf  \n",
       "7             the most wonderful gingerbread cookies  \n",
       "8                                  best banana bread  \n",
       "9                   impossible peanut butter cookies  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the recipe names for each recipe_id\n",
    "# Load recipe data\n",
    "raw_recipes = pd.read_csv(path + \"RAW_recipes.csv\", sep=\",\")\n",
    "\n",
    "# Define function that returns recipe name when given a recipe id\n",
    "def get_recipe_name(recipe_id):\n",
    "    return raw_recipes[raw_recipes[\"id\"] == recipe_id][\"name\"].item()\n",
    "\n",
    "# Apply this function to every row of the recommendations dataframe (with apply and lambda)\n",
    "recommendations[\"recipe_name\"] = recommendations.apply(lambda x: get_recipe_name(x[\"recipe_id\"]), axis=1)\n",
    "recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
