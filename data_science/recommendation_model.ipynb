{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leaed\\anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/leaed/Documents/Techlabs/Mealwheeldata/\"\n",
    "raw_interactions = pd.read_csv(path + \"RAW_interactions.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_interactions = raw_interactions[raw_interactions.rating > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_interactions = raw_interactions[[\"user_id\", \"recipe_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightFM will not use our IDs, but rather internal indices\n",
    "# It does this, because it needs consecutive non-negative integers (but the input could be anything)\n",
    "# Therefore, we need a mapping between our IDs and the internal indices\n",
    "# E.g. user_id = 38094 -> internal_user_id = 1, user_id = 1293707 -> internal_user_id = 2\n",
    "# Very well explained: https://making.lyst.com/lightfm/docs/examples/dataset.html?highlight=dataset\n",
    "#building-the-id-mappings\n",
    "\n",
    "# We can do this easily by using the Dataset class from the LightFM package\n",
    "dataset = Dataset()\n",
    "dataset.fit(users=raw_interactions[\"user_id\"], items=raw_interactions[\"recipe_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To have an easy way of converting input ids to internal ids, we define a mappings class\n",
    "class Mappings:\n",
    "    def __init__(self, dataset: Dataset) -> None:\n",
    "        \"\"\"\n",
    "        userid: user_id\n",
    "        row: internal user id\n",
    "        itemid: recipe_id\n",
    "        column: internal recipe id\n",
    "        \"\"\"\n",
    "        userid2row, _, itemid2col, _ = dataset.mapping()\n",
    "        self.userid2row = userid2row\n",
    "        self.itemid2col = itemid2col\n",
    "        # Invert dictionaries to get mapping in other direction\n",
    "        self.row2userid = {value: key for key, value in self.userid2row.items()}\n",
    "        self.col2itemid = {v: k for k, v in self.itemid2col.items()}\n",
    "        # Use like this: \n",
    "        # mappings = Mappings(dataset)\n",
    "        # mappings.userid2row[\"axfafe24\"]\n",
    "\n",
    "# And use it:\n",
    "mappings = Mappings(dataset)\n",
    "# Example. This returns the internal user id of user_id=38094\n",
    "mappings.userid2row[1293707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "class LightFMResizable(LightFM):\n",
    "    \"\"\"A LightFM that resizes the model to accomodate new users,\n",
    "    items, and features\"\"\"\n",
    "\n",
    "    def fit_partial(\n",
    "        self,\n",
    "        interactions,\n",
    "        user_features=None,\n",
    "        item_features=None,\n",
    "        sample_weight=None,\n",
    "        epochs=1,\n",
    "        num_threads=1,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        try:\n",
    "            self._check_initialized()\n",
    "            self._resize(interactions, user_features, item_features)\n",
    "        except ValueError:\n",
    "            # This is the first call so just fit without resizing\n",
    "            pass\n",
    "\n",
    "        super().fit_partial(\n",
    "            interactions,\n",
    "            user_features,\n",
    "            item_features,\n",
    "            sample_weight,\n",
    "            epochs,\n",
    "            num_threads,\n",
    "            verbose,\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _resize(self, interactions, user_features=None, item_features=None):\n",
    "        \"\"\"Resizes the model to accommodate new users/items/features\"\"\"\n",
    "\n",
    "        no_components = self.no_components\n",
    "        no_user_features, no_item_features = interactions.shape  # default\n",
    "\n",
    "        if hasattr(user_features, \"shape\"):\n",
    "            no_user_features = user_features.shape[-1]\n",
    "        if hasattr(item_features, \"shape\"):\n",
    "            no_item_features = item_features.shape[-1]\n",
    "\n",
    "        if (\n",
    "            no_user_features == self.user_embeddings.shape[0]\n",
    "            and no_item_features == self.item_embeddings.shape[0]\n",
    "        ):\n",
    "            return self\n",
    "\n",
    "        new_model = clone(self)\n",
    "        new_model._initialize(no_components, no_item_features, no_user_features)\n",
    "\n",
    "        # update all attributes from self._check_initialized\n",
    "        for attr in (\n",
    "            \"item_embeddings\",\n",
    "            \"item_embedding_gradients\",\n",
    "            \"item_embedding_momentum\",\n",
    "            \"item_biases\",\n",
    "            \"item_bias_gradients\",\n",
    "            \"item_bias_momentum\",\n",
    "            \"user_embeddings\",\n",
    "            \"user_embedding_gradients\",\n",
    "            \"user_embedding_momentum\",\n",
    "            \"user_biases\",\n",
    "            \"user_bias_gradients\",\n",
    "            \"user_bias_momentum\",\n",
    "        ):\n",
    "            # extend attribute matrices with new rows/cols from\n",
    "            # freshly initialized model with right shape\n",
    "            old_array = getattr(self, attr)\n",
    "            old_slice = [slice(None, i) for i in old_array.shape]\n",
    "            new_array = getattr(new_model, attr)\n",
    "            new_array[tuple(old_slice)] = old_array\n",
    "            setattr(self, attr, new_array)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we build the interaction matrix (a table with users as rows and recipes as columns, and a 1 in the cell if the user rated the recipe)\n",
    "interactions, _ = dataset.build_interactions(raw_interactions.to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could also add item_features (like the ratings)\n",
    "# https://making.lyst.com/lightfm/docs/examples/dataset.html?highlight=dataset#building-the-interactions-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can raw_datae model\n",
    "# This might take a few minutes\n",
    "model = LightFMResizable(loss=\"warp\", learning_rate=0.05, random_state=42)\n",
    "model.fit(interactions=interactions, epochs=100)\n",
    "\n",
    "# Save model to pickle file\n",
    "filename = \"recommendation_model.pkl\"\n",
    "with open(filename, 'wb') as file:  \n",
    "     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Adrian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(a, new_user_recipe_ids):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    a: number of recommendations you want\n",
    "    new_user_recipe_ids: list 5 liked recipe_ids\n",
    "    Output:\n",
    "    output: a recommendations as a json format\n",
    "    \n",
    "    Model is in a pickle file\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Load model from pickle file\n",
    "    filename = \"recommendation_model.pkl\" \n",
    "    with open(filename, 'rb') as file:  \n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    ### fit_partial new user\n",
    "    new_user = pd.DataFrame({\n",
    "        \"user_id\":  [1,1,1,1,1], \n",
    "        \"recipe_id\":  new_user_recipe_id})\n",
    "    dataset.fit_partial(users=new_user[\"user_id\"], items=new_user[\"recipe_id\"])\n",
    "    new_interactions, _ = dataset.build_interactions(new_user.to_records(index=False))\n",
    "    model.fit_partial(interactions=new_interactions)\n",
    "\n",
    "    ### Get recommendations for this user\n",
    "    user_id = 1\n",
    "    # Get the internal id (or: row) for this user\n",
    "    user_row = mappings.userid2row[user_id]\n",
    "    # Get the number of items in the dataset\n",
    "    _, n_items = dataset.interactions_shape()\n",
    "    # Get an array with all internal item ids\n",
    "    item_columns = np.arange(n_items) # [0, 1, 2, ..., 231636]\n",
    "    # Get the scores for each item (for our user)\n",
    "    scores = model.predict(user_ids=user_row, item_ids=item_columns)\n",
    "    # Define a function that sorts the scores and returns the top_n elements\n",
    "    def get_top_sorted(scores: np.ndarray, top_n):\n",
    "        \"\"\"\n",
    "        Get the top indices sorted descendingly from the scores list array.\n",
    "        Args:\n",
    "        scores: An array with scores.\n",
    "        top_n: The number of top scores to be returned.\n",
    "        Returns:\n",
    "            ScoringList: The first element of the tuple is the index where the score was\n",
    "                    in the original array, the second element is the score itself.\n",
    "        \"\"\"\n",
    "        best_idxs = np.argpartition(scores, -top_n)[-top_n:]\n",
    "        return sorted(zip(best_idxs, scores[best_idxs]), key=lambda x: -x[1])\n",
    "    \n",
    "    sorted_scores_top = get_top_sorted(scores, a)\n",
    "    \n",
    "    # Add results to a DataFrame\n",
    "    recommendations = pd.DataFrame(sorted_scores_top, columns=[\"internal_item_id\", \"score\"])\n",
    "    # Add user_id\n",
    "    recommendations[\"user_id\"] = user_id\n",
    "    # Add recipe_id\n",
    "    # Google something like \"python apply lambda\" to learn more about how this works\n",
    "    recommendations[\"recipe_id\"] = recommendations[\"internal_item_id\"].apply(lambda x: mappings.col2itemid[x])\n",
    "    # Drop internal_item_id and reorder other columns\n",
    "    recommendations = recommendations[[\"user_id\", \"recipe_id\", \"score\"]]\n",
    "    ## Get the names of the recipes our sample user\n",
    "    # Get all interactions from out test user\n",
    "    user_recipes = raw_interactions[raw_interactions[\"user_id\"] == user_id]\n",
    "\n",
    "    # Apply function from above also to this dataframe\n",
    "    user_recipes[\"recipe_name\"] = user_recipes.apply(lambda x: get_recipe_name(x[\"recipe_id\"]), axis=1)\n",
    "    raw_recipes = pd.read_csv( \"C:/Users/leaed/Documents/Techlabs/Mealwheeldata/RAW_recipes.csv\", sep=\",\")\n",
    "    \n",
    "    to_adrian = user_recipes.set_index('recipe_id').join(raw_recipes.set_index('id'))\n",
    "    to_adrian.drop(['name'], axis = 1, inplace = True)\n",
    "    to_adrian.drop(['contributor_id'], axis = 1, inplace = True)\n",
    "    to_adrian.drop(['submitted'], axis = 1, inplace = True)\n",
    "    to_adrian.drop(['user_id'], axis = 1, inplace = True)\n",
    "\n",
    "    ### Convert to json \n",
    "    output = to_adrian.to_json(orient=\"records\")\n",
    "    \n",
    "    ### return json\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_recipe_id = [4065, 10123, 295797, 108524, 10045]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 2, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'recipe_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3573\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3574\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3575\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'recipe_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-07dc8e28d7bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_user_recipe_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-996beaa6356d>\u001b[0m in \u001b[0;36mget_recommendations\u001b[1;34m(a, new_user_recipe_ids)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# Apply function from above also to this dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0muser_recipes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"recipe_name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_recipes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_recipe_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"recipe_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[0mraw_recipes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"C:/Users/leaed/Documents/Techlabs/Mealwheeldata/RAW_recipes.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3040\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3116\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3117\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3119\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3575\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3576\u001b[0m             \u001b[1;31m# This item wasn't present, just insert at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3577\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3578\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[0;32m   2720\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2722\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    131\u001b[0m                 \u001b[1;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 2, placement implies 1"
     ]
    }
   ],
   "source": [
    "get_recommendations(1, new_user_recipe_ids)\n",
    "# maybe that helps: https://stackoverflow.com/questions/43196907/valueerror-wrong-number-of-items-passed-meaning-and-suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fit partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = pd.DataFrame({\n",
    "    \"user_id\":  [1,1,1,1,1],\n",
    "    \"recipe_id\":  [4065, 10123, 295797, 108524, 10045]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fit_partial(users=new_user[\"user_id\"], items=new_user[\"recipe_id\"])\n",
    "new_interactions, _ = dataset.build_interactions(new_user.to_records(index=False))\n",
    "\n",
    "# In production update your old model with new data.\n",
    "model.fit_partial(interactions=new_interactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "Get recommendations for one sample user and check if the recommendations make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0169863, -1.3943113, -1.1754183, ..., -2.5216193, -2.3398874,\n",
       "       -1.7851042], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the user for which predictions should be made\n",
    "user_id = 2001868099\n",
    "# Get the internal id (or: row) for this user\n",
    "user_row = mappings.userid2row[user_id]\n",
    "# Get the number of items in the dataset\n",
    "_, n_items = dataset.interactions_shape()\n",
    "# Get an array with all internal item ids\n",
    "item_columns = np.arange(n_items) # [0, 1, 2, ..., 231636]\n",
    "# Get the scores for each item (for our user)\n",
    "scores = model.predict(user_ids=user_row, item_ids=item_columns)\n",
    "# How to interpret:\n",
    "# score[0] = recommendation score for internal item id 0\n",
    "# score[1] = recommendation score for internal item id 1\n",
    "# ...\n",
    "# The item with the highest score is most likely to be a good recommendation\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2feafc04b267>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define a function that sorts the scores and returns the top_n elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mget_top_sorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \"\"\"\n\u001b[0;32m      4\u001b[0m     \u001b[0mGet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtop\u001b[0m \u001b[0mindices\u001b[0m \u001b[0msorted\u001b[0m \u001b[0mdescendingly\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscores\u001b[0m \u001b[0mlist\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a function that sorts the scores and returns the top_n elements\n",
    "def get_top_sorted(scores: np.ndarray, top_n):\n",
    "    \"\"\"\n",
    "    Get the top indices sorted descendingly from the scores list array.\n",
    "    Args:\n",
    "        scores: An array with scores.\n",
    "        top_n: The number of top scores to be returned.\n",
    "    Returns:\n",
    "        ScoringList: The first element of the tuple is the index where the score was\n",
    "                in the original array, the second element is the score itself.\n",
    "    \"\"\"\n",
    "    best_idxs = np.argpartition(scores, -top_n)[-top_n:]\n",
    "    return sorted(zip(best_idxs, scores[best_idxs]), key=lambda x: -x[1])\n",
    "\n",
    "# Example: Use fuction to return top 5 recommendations\n",
    "sorted_scores_top_10 = get_top_sorted(scores, 10)\n",
    "sorted_scores_top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>27208</td>\n",
       "      <td>2.071391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>97496</td>\n",
       "      <td>2.042040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>39087</td>\n",
       "      <td>1.923201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>32204</td>\n",
       "      <td>1.906267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>67256</td>\n",
       "      <td>1.885892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>89204</td>\n",
       "      <td>1.859283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>54257</td>\n",
       "      <td>1.831842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>80156</td>\n",
       "      <td>1.797088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>2886</td>\n",
       "      <td>1.778458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>15411</td>\n",
       "      <td>1.758239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  recipe_id     score\n",
       "0  2001868099      27208  2.071391\n",
       "1  2001868099      97496  2.042040\n",
       "2  2001868099      39087  1.923201\n",
       "3  2001868099      32204  1.906267\n",
       "4  2001868099      67256  1.885892\n",
       "5  2001868099      89204  1.859283\n",
       "6  2001868099      54257  1.831842\n",
       "7  2001868099      80156  1.797088\n",
       "8  2001868099       2886  1.778458\n",
       "9  2001868099      15411  1.758239"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add results to a DataFrame\n",
    "recommendations = pd.DataFrame(sorted_scores_top_10, columns=[\"internal_item_id\", \"score\"])\n",
    "# Add user_id\n",
    "recommendations[\"user_id\"] = user_id\n",
    "# Add recipe_id\n",
    "# Google something like \"python apply lambda\" to learn more about how this works\n",
    "recommendations[\"recipe_id\"] = recommendations[\"internal_item_id\"].apply(lambda x: mappings.col2itemid[x])\n",
    "# Drop internal_item_id and reorder other columns\n",
    "recommendations = recommendations[[\"user_id\", \"recipe_id\", \"score\"]]\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>score</th>\n",
       "      <th>recipe_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>27208</td>\n",
       "      <td>2.071391</td>\n",
       "      <td>to die for crock pot roast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>97496</td>\n",
       "      <td>2.042040</td>\n",
       "      <td>soft snickerdoodle cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>39087</td>\n",
       "      <td>1.923201</td>\n",
       "      <td>creamy cajun chicken pasta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>32204</td>\n",
       "      <td>1.906267</td>\n",
       "      <td>whatever floats your boat  brownies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>67256</td>\n",
       "      <td>1.885892</td>\n",
       "      <td>best ever banana cake with cream cheese frosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>89204</td>\n",
       "      <td>1.859283</td>\n",
       "      <td>crock pot chicken with black beans   cream cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>54257</td>\n",
       "      <td>1.831842</td>\n",
       "      <td>yes  virginia there is a great meatloaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>80156</td>\n",
       "      <td>1.797088</td>\n",
       "      <td>the most wonderful gingerbread cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>2886</td>\n",
       "      <td>1.778458</td>\n",
       "      <td>best banana bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>15411</td>\n",
       "      <td>1.758239</td>\n",
       "      <td>impossible peanut butter cookies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  recipe_id     score  \\\n",
       "0  2001868099      27208  2.071391   \n",
       "1  2001868099      97496  2.042040   \n",
       "2  2001868099      39087  1.923201   \n",
       "3  2001868099      32204  1.906267   \n",
       "4  2001868099      67256  1.885892   \n",
       "5  2001868099      89204  1.859283   \n",
       "6  2001868099      54257  1.831842   \n",
       "7  2001868099      80156  1.797088   \n",
       "8  2001868099       2886  1.778458   \n",
       "9  2001868099      15411  1.758239   \n",
       "\n",
       "                                         recipe_name  \n",
       "0                         to die for crock pot roast  \n",
       "1                         soft snickerdoodle cookies  \n",
       "2                         creamy cajun chicken pasta  \n",
       "3                whatever floats your boat  brownies  \n",
       "4   best ever banana cake with cream cheese frosting  \n",
       "5  crock pot chicken with black beans   cream cheese  \n",
       "6            yes  virginia there is a great meatloaf  \n",
       "7             the most wonderful gingerbread cookies  \n",
       "8                                  best banana bread  \n",
       "9                   impossible peanut butter cookies  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the recipe names for each recipe_id\n",
    "# Load recipe data\n",
    "raw_recipes = pd.read_csv(path + \"RAW_recipes.csv\", sep=\",\")\n",
    "\n",
    "# Define function that returns recipe name when given a recipe id\n",
    "def get_recipe_name(recipe_id):\n",
    "    return raw_recipes[raw_recipes[\"id\"] == recipe_id][\"name\"].item()\n",
    "\n",
    "# Apply this function to every row of the recommendations dataframe (with apply and lambda)\n",
    "recommendations[\"recipe_name\"] = recommendations.apply(lambda x: get_recipe_name(x[\"recipe_id\"]), axis=1)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_recipes = pd.read_csv(path + \"RAW_recipes.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"['60-minutes-or-less', 'time-to-make', 'course', 'main-ingredient', 'cuisine', 'preparation', 'occasion', 'north-american', 'side-dishes', 'vegetables', 'mexican', 'easy', 'fall', 'holiday-event', 'vegetarian', 'winter', 'dietary', 'christmas', 'seasonal', 'squash']\",\n",
       "       \"['30-minutes-or-less', 'time-to-make', 'course', 'main-ingredient', 'cuisine', 'preparation', 'occasion', 'north-american', 'breakfast', 'main-dish', 'pork', 'american', 'oven', 'easy', 'kid-friendly', 'pizza', 'dietary', 'northeastern-united-states', 'meat', 'equipment']\",\n",
       "       \"['time-to-make', 'course', 'preparation', 'main-dish', 'chili', 'crock-pot-slow-cooker', 'dietary', 'equipment', '4-hours-or-less']\",\n",
       "       ...,\n",
       "       \"['60-minutes-or-less', 'time-to-make', 'course', 'main-ingredient', 'preparation', 'appetizers', 'eggs-dairy', 'easy', 'finger-food', 'eggs', 'presentation', 'served-cold', '3-steps-or-less']\",\n",
       "       \"['30-minutes-or-less', 'time-to-make', 'course', 'preparation', 'for-large-groups', 'hand-formed-cookies', 'desserts', 'cookies-and-brownies', 'dietary', 'high-calcium', 'high-in-something', 'number-of-servings']\",\n",
       "       \"['30-minutes-or-less', 'time-to-make', 'course', 'preparation', 'occasion', 'for-large-groups', 'rolled-cookies', 'desserts', 'kid-friendly', 'cookies-and-brownies', 'dietary', 'comfort-food', 'taste-mood', 'sweet', 'number-of-servings']\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_recipes.tags.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2886      1613\n",
       "27208     1601\n",
       "89204     1579\n",
       "39087     1448\n",
       "67256     1322\n",
       "54257     1305\n",
       "22782     1234\n",
       "32204     1220\n",
       "69173      997\n",
       "68955      904\n",
       "33919      877\n",
       "82102      855\n",
       "25885      847\n",
       "28148      802\n",
       "135350     786\n",
       "26110      770\n",
       "99476      762\n",
       "10744      731\n",
       "129926     730\n",
       "33671      727\n",
       "Name: recipe_id, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_interactions['recipe_id'].value_counts().head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
