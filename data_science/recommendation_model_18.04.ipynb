{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leaed\\anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mappings:\n",
    "    def __init__(self, dataset: Dataset) -> None:\n",
    "        \"\"\"\n",
    "        userid: user_id\n",
    "        row: internal user id\n",
    "        itemid: recipe_id\n",
    "        column: internal recipe id\n",
    "        \"\"\"\n",
    "        userid2row, _, itemid2col, _ = dataset.mapping()\n",
    "        self.userid2row = userid2row\n",
    "        self.itemid2col = itemid2col\n",
    "        # Invert dictionaries to get mapping in other direction\n",
    "        self.row2userid = {value: key for key, value in self.userid2row.items()}\n",
    "        self.col2itemid = {v: k for k, v in self.itemid2col.items()}\n",
    "\n",
    "class LightFMResizable(LightFM):\n",
    "    \"\"\"A LightFM that resizes the model to accomodate new users,\n",
    "    items, and features\"\"\"\n",
    "\n",
    "    def fit_partial(\n",
    "        self,\n",
    "        interactions,\n",
    "        user_features=None,\n",
    "        item_features=None,\n",
    "        sample_weight=None,\n",
    "        epochs=1,\n",
    "        num_threads=1,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        try:\n",
    "            self._check_initialized()\n",
    "            self._resize(interactions, user_features, item_features)\n",
    "        except ValueError:\n",
    "            # This is the first call so just fit without resizing\n",
    "            pass\n",
    "\n",
    "        super().fit_partial(\n",
    "            interactions,\n",
    "            user_features,\n",
    "            item_features,\n",
    "            sample_weight,\n",
    "            epochs,\n",
    "            num_threads,\n",
    "            verbose,\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _resize(self, interactions, user_features=None, item_features=None):\n",
    "        \"\"\"Resizes the model to accommodate new users/items/features\"\"\"\n",
    "\n",
    "        no_components = self.no_components\n",
    "        no_user_features, no_item_features = interactions.shape  # default\n",
    "\n",
    "        if hasattr(user_features, \"shape\"):\n",
    "            no_user_features = user_features.shape[-1]\n",
    "        if hasattr(item_features, \"shape\"):\n",
    "            no_item_features = item_features.shape[-1]\n",
    "\n",
    "        if (\n",
    "            no_user_features == self.user_embeddings.shape[0]\n",
    "            and no_item_features == self.item_embeddings.shape[0]\n",
    "        ):\n",
    "            return self\n",
    "\n",
    "        new_model = clone(self)\n",
    "        new_model._initialize(no_components, no_item_features, no_user_features)\n",
    "\n",
    "        # update all attributes from self._check_initialized\n",
    "        for attr in (\n",
    "            \"item_embeddings\",\n",
    "            \"item_embedding_gradients\",\n",
    "            \"item_embedding_momentum\",\n",
    "            \"item_biases\",\n",
    "            \"item_bias_gradients\",\n",
    "            \"item_bias_momentum\",\n",
    "            \"user_embeddings\",\n",
    "            \"user_embedding_gradients\",\n",
    "            \"user_embedding_momentum\",\n",
    "            \"user_biases\",\n",
    "            \"user_bias_gradients\",\n",
    "            \"user_bias_momentum\",\n",
    "        ):\n",
    "            # extend attribute matrices with new rows/cols from\n",
    "            # freshly initialized model with right shape\n",
    "            old_array = getattr(self, attr)\n",
    "            old_slice = [slice(None, i) for i in old_array.shape]\n",
    "            new_array = getattr(new_model, attr)\n",
    "            new_array[tuple(old_slice)] = old_array\n",
    "            setattr(self, attr, new_array)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted(scores: np.ndarray, top_n):\n",
    "        \"\"\"\n",
    "        Get the top indices sorted descendingly from the scores list array.\n",
    "        Args:\n",
    "        scores: An array with scores.\n",
    "        Returns:\n",
    "            ScoringList: The first element of the tuple is the index where the score was\n",
    "                    in the original array, the second element is the score itself.\n",
    "        \"\"\"\n",
    "        best_idxs = np.argpartition(scores, -top_n)[-top_n:]\n",
    "        return sorted(zip(best_idxs, scores[best_idxs]), key=lambda x: -x[1])\n",
    "def load_data(path=\"\"):\n",
    "    \"\"\"\n",
    "    Loads the following files:\n",
    "        raw_recipes\n",
    "        model    Params:\n",
    "        path: Path to folder with the files. If path=\"\", files must be in the same folder as this notebook.\n",
    "    \"\"\"\n",
    "    raw_recipes = pd.read_csv(path + \"RAW_recipes.csv\", sep=\",\")\n",
    "    filename = \"dataset.pkl\"\n",
    "    with open(path + filename, 'rb') as file:\n",
    "        dataset = pickle.load(file)\n",
    "    filename = \"recommendation_model.pkl\"\n",
    "    with open(path + filename, 'rb') as file:\n",
    "        model = pickle.load(file)   \n",
    "    mappings = Mappings(dataset)\n",
    "    return raw_recipes,mappings, model, dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function get_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(a, new_user_recipe_ids, path, tag):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    a: number of recommendations you want\n",
    "    new_user_recipe_ids: list 5 liked recipe_id\n",
    "    path: Path to folder with the files. If path=\"\", files must be in the same folder as this notebook\n",
    "    tag: vegan, vegetarian or pig\n",
    "    Output:\n",
    "    output: a recommendations as a json format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    raw_recipes, mappings, model, dataset = load_data(path)\n",
    "    \n",
    "    # fit_partial new user\n",
    "    new_user = pd.DataFrame({\n",
    "        \"user_id\":  [1] * len(new_user_recipe_id), \n",
    "        \"recipe_id\":  new_user_recipe_id})\n",
    "    dataset.fit_partial(users=new_user[\"user_id\"], items=new_user[\"recipe_id\"])\n",
    "    new_interactions, _ = dataset.build_interactions(new_user.to_records(index=False))\n",
    "    model.fit_partial(interactions=new_interactions)\n",
    "\n",
    "    user_id = 1\n",
    "    # Get the internal id (or: row) for this user, the number of items in the dataset & the scores for each item (for our user)\n",
    "    user_row = mappings.userid2row[user_id]\n",
    "    _, n_items = dataset.interactions_shape()\n",
    "    item_columns = np.arange(n_items)\n",
    "    scores = model.predict(user_ids=user_row, item_ids=item_columns)\n",
    "            \n",
    "    sorted_scores_top = get_top_sorted(scores, a)\n",
    "    \n",
    "    # Add results to a DataFrame\n",
    "    recommendations = pd.DataFrame(sorted_scores_top, columns=[\"internal_item_id\", \"score\"])\n",
    "    recommendations[\"user_id\"] = user_id\n",
    "    recommendations[\"recipe_id\"] = recommendations[\"internal_item_id\"].apply(lambda x: mappings.col2itemid[x])\n",
    "    recommendations = recommendations[[\"user_id\", \"recipe_id\", \"score\"]]\n",
    "    \n",
    "    to_adrian = recommendations.set_index('recipe_id').join(raw_recipes.set_index('id'))\n",
    "    to_adrian.drop(['name'], axis = 1, inplace = True)\n",
    "    to_adrian.drop(['contributor_id'], axis = 1, inplace = True)\n",
    "    to_adrian.drop(['submitted'], axis = 1, inplace = True)\n",
    "    to_adrian.drop(['user_id'], axis = 1, inplace = True)\n",
    "    to_adrian.reset_index(inplace=True)\n",
    "    \n",
    "    #filter via tags\n",
    "    to_adrian[\"tags\"] = to_adrian[\"tags\"].apply(eval)\n",
    "    #entweder\n",
    "    x = 0\n",
    "    while x < 3:\n",
    "        not_in_list = tag not in to_adrian.iloc[x][\"tags\"]\n",
    "        if not_in_list == True:\n",
    "            to_adrian.drop([x], inplace=True, axis=0)\n",
    "        x = x + 1\n",
    "    #oder    \n",
    "    for x in range(len(to_adrian.index)):\n",
    "        not_in_list = tag not in to_adrian.iloc[x][\"tags\"]\n",
    "        if not_in_list == True:\n",
    "            to_adrian.drop([x], inplace=True, axis=0)\n",
    "    # evtl a erst hier einsetzen -> davor alle recommendations filtern und erst jetzt auf Anzahl a begrenzen\n",
    "    #sorted_scores_top = get_top_sorted(scores, a)\n",
    "            \n",
    "    # Convert to json \n",
    "    output = to_adrian.to_json(orient=\"records\")\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random recipe_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_recipe_ids(n, path):\n",
    "    \"\"\"\n",
    "    n: number of random recipe_ids\n",
    "    path: Path to folder with the files. If path=\"\", files must be in the same folder as this notebook\n",
    "    Returns: n random recipe_ids\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    raw_recipes = load_data(path)\n",
    "    #random = raw_interactions.loc[raw_interactions['rating'] == 5]\n",
    "    #random = raw_recipes['id'].sample(n)\n",
    "    random = raw_recipes.sample(n,replace=True)\n",
    "    #random1 = random.to_frame()\n",
    "    return random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-9f2bbbbcc47b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandom_recipe_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"C:/Users/leaed/Documents/Techlabs/Mealwheeldata/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-85-7a7427c1832c>\u001b[0m in \u001b[0;36mrandom_recipe_ids\u001b[1;34m(n, path)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#random = raw_interactions.loc[raw_interactions['rating'] == 5]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#random = raw_recipes['id'].sample(n)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mrandom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_recipes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m#random1 = random.to_frame()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "random_recipe_ids(3,\"C:/Users/leaed/Documents/Techlabs/Mealwheeldata/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>score</th>\n",
       "      <th>minutes</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415097</td>\n",
       "      <td>2.248046</td>\n",
       "      <td>10</td>\n",
       "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[111.8, 10.0, 41.0, 2.0, 3.0, 14.0, 3.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>['stir together the hot espresso , creamer , a...</td>\n",
       "      <td>trying to stay away from the coffee shops and ...</td>\n",
       "      <td>['brewed espresso', 'non-dairy coffee creamer'...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55457</td>\n",
       "      <td>2.150353</td>\n",
       "      <td>60</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[6989.2, 472.0, 2778.0, 163.0, 155.0, 934.0, 3...</td>\n",
       "      <td>19</td>\n",
       "      <td>['preheat oven to 325 and butter two 9 inch ro...</td>\n",
       "      <td>as soon as i tasted this i had to get onto ema...</td>\n",
       "      <td>['flour', 'baking soda', 'salt', 'butter', 'gr...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103760</td>\n",
       "      <td>2.131980</td>\n",
       "      <td>10</td>\n",
       "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[275.0, 0.0, 233.0, 295.0, 13.0, 0.0, 21.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['boil water with vinegar and sugar', 'allow i...</td>\n",
       "      <td>dipping sauce posted in response to a request....</td>\n",
       "      <td>['water', 'rice vinegar', 'sugar', 'fish sauce...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id     score  minutes  \\\n",
       "0     415097  2.248046       10   \n",
       "1      55457  2.150353       60   \n",
       "2     103760  2.131980       10   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
       "1  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "2  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                           nutrition  n_steps  \\\n",
       "0           [111.8, 10.0, 41.0, 2.0, 3.0, 14.0, 3.0]        3   \n",
       "1  [6989.2, 472.0, 2778.0, 163.0, 155.0, 934.0, 3...       19   \n",
       "2        [275.0, 0.0, 233.0, 295.0, 13.0, 0.0, 21.0]        4   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['stir together the hot espresso , creamer , a...   \n",
       "1  ['preheat oven to 325 and butter two 9 inch ro...   \n",
       "2  ['boil water with vinegar and sugar', 'allow i...   \n",
       "\n",
       "                                         description  \\\n",
       "0  trying to stay away from the coffee shops and ...   \n",
       "1  as soon as i tasted this i had to get onto ema...   \n",
       "2  dipping sauce posted in response to a request....   \n",
       "\n",
       "                                         ingredients  n_ingredients  \n",
       "0  ['brewed espresso', 'non-dairy coffee creamer'...              5  \n",
       "1  ['flour', 'baking soda', 'salt', 'butter', 'gr...             13  \n",
       "2  ['water', 'rice vinegar', 'sugar', 'fish sauce...              6  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_recipe_id = [4065, 10123, 295797, 108524, 10045]\n",
    "get_recommendations(3, new_user_recipe_id, \"C:/Users/leaed/Documents/Techlabs/Mealwheeldata/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
