{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mappings:\n",
    "    def __init__(self, dataset: Dataset) -> None:\n",
    "        \"\"\"\n",
    "        userid: user_id\n",
    "        row: internal user id\n",
    "        itemid: recipe_id\n",
    "        column: internal recipe id\n",
    "        \"\"\"\n",
    "        userid2row, _, itemid2col, _ = dataset.mapping()\n",
    "        self.userid2row = userid2row\n",
    "        self.itemid2col = itemid2col\n",
    "        # Invert dictionaries to get mapping in other direction\n",
    "        self.row2userid = {value: key for key, value in self.userid2row.items()}\n",
    "        self.col2itemid = {v: k for k, v in self.itemid2col.items()}\n",
    "\n",
    "class LightFMResizable(LightFM):\n",
    "    \"\"\"A LightFM that resizes the model to accomodate new users,\n",
    "    items, and features\"\"\"\n",
    "\n",
    "    def fit_partial(\n",
    "        self,\n",
    "        interactions,\n",
    "        user_features=None,\n",
    "        item_features=None,\n",
    "        sample_weight=None,\n",
    "        epochs=1,\n",
    "        num_threads=1,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        try:\n",
    "            self._check_initialized()\n",
    "            self._resize(interactions, user_features, item_features)\n",
    "        except ValueError:\n",
    "            # This is the first call so just fit without resizing\n",
    "            pass\n",
    "\n",
    "        super().fit_partial(\n",
    "            interactions,\n",
    "            user_features,\n",
    "            item_features,\n",
    "            sample_weight,\n",
    "            epochs,\n",
    "            num_threads,\n",
    "            verbose,\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _resize(self, interactions, user_features=None, item_features=None):\n",
    "        \"\"\"Resizes the model to accommodate new users/items/features\"\"\"\n",
    "\n",
    "        no_components = self.no_components\n",
    "        no_user_features, no_item_features = interactions.shape  # default\n",
    "\n",
    "        if hasattr(user_features, \"shape\"):\n",
    "            no_user_features = user_features.shape[-1]\n",
    "        if hasattr(item_features, \"shape\"):\n",
    "            no_item_features = item_features.shape[-1]\n",
    "\n",
    "        if (\n",
    "            no_user_features == self.user_embeddings.shape[0]\n",
    "            and no_item_features == self.item_embeddings.shape[0]\n",
    "        ):\n",
    "            return self\n",
    "\n",
    "        new_model = clone(self)\n",
    "        new_model._initialize(no_components, no_item_features, no_user_features)\n",
    "\n",
    "        # update all attributes from self._check_initialized\n",
    "        for attr in (\n",
    "            \"item_embeddings\",\n",
    "            \"item_embedding_gradients\",\n",
    "            \"item_embedding_momentum\",\n",
    "            \"item_biases\",\n",
    "            \"item_bias_gradients\",\n",
    "            \"item_bias_momentum\",\n",
    "            \"user_embeddings\",\n",
    "            \"user_embedding_gradients\",\n",
    "            \"user_embedding_momentum\",\n",
    "            \"user_biases\",\n",
    "            \"user_bias_gradients\",\n",
    "            \"user_bias_momentum\",\n",
    "        ):\n",
    "            # extend attribute matrices with new rows/cols from\n",
    "            # freshly initialized model with right shape\n",
    "            old_array = getattr(self, attr)\n",
    "            old_slice = [slice(None, i) for i in old_array.shape]\n",
    "            new_array = getattr(new_model, attr)\n",
    "            new_array[tuple(old_slice)] = old_array\n",
    "            setattr(self, attr, new_array)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted(scores: np.ndarray, top_n):\n",
    "        \"\"\"\n",
    "        Get the top indices sorted descendingly from the scores list array.\n",
    "        Args:\n",
    "        scores: An array with scores.\n",
    "        Returns:\n",
    "            ScoringList: The first element of the tuple is the index where the score was\n",
    "                    in the original array, the second element is the score itself.\n",
    "        \"\"\"\n",
    "        best_idxs = np.argpartition(scores, -top_n)[-top_n:]\n",
    "        return sorted(zip(best_idxs, scores[best_idxs]), key=lambda x: -x[1])\n",
    "def load_data(path=\"\"):\n",
    "    \"\"\"\n",
    "    Loads the following files:\n",
    "        raw_recipes\n",
    "        model    Params:\n",
    "        path: Path to folder with the files. If path=\"\", files must be in the same folder as this notebook.\n",
    "    \"\"\"\n",
    "    raw_recipes = pd.read_csv(path + \"RAW_recipes.csv\", sep=\",\")\n",
    "    filename = \"dataset.pkl\"\n",
    "    with open(path + filename, 'rb') as file:\n",
    "        dataset = pickle.load(file)\n",
    "    filename = \"recommendation_model.pkl\"\n",
    "    with open(path + filename, 'rb') as file:\n",
    "        model = pickle.load(file)   \n",
    "    mappings = Mappings(dataset)\n",
    "    return raw_recipes,mappings, model, dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function get_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(a, new_user_recipe_ids, path):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    a: number of recommendations you want\n",
    "    new_user_recipe_ids: list 5 liked recipe_id\n",
    "    path: Path to folder with the files. If path=\"\", files must be in the same folder as this notebook\n",
    "    tag: vegan, vegetarian or pig\n",
    "    Output:\n",
    "    recommendations: a recommendations as a json format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    raw_recipes, mappings, model, dataset = load_data(path)\n",
    "    \n",
    "    # fit_partial new user\n",
    "    new_user = pd.DataFrame({\n",
    "        \"user_id\":  [1] * len(new_user_recipe_id), \n",
    "        \"recipe_id\":  new_user_recipe_id})\n",
    "    dataset.fit_partial(users=new_user[\"user_id\"], items=new_user[\"recipe_id\"])\n",
    "    new_interactions, _ = dataset.build_interactions(new_user.to_records(index=False))\n",
    "    model.fit_partial(interactions=new_interactions)\n",
    "\n",
    "    user_id = 1\n",
    "    # Get the internal id (or: row) for this user, the number of items in the dataset & the scores for each item (for our user)\n",
    "    user_row = mappings.userid2row[user_id]\n",
    "    _, n_items = dataset.interactions_shape()\n",
    "    item_columns = np.arange(n_items)\n",
    "    scores = model.predict(user_ids=user_row, item_ids=item_columns)\n",
    "            \n",
    "    sorted_scores_top = get_top_sorted(scores, a)\n",
    "    \n",
    "    # Add results to a DataFrame\n",
    "    recommendations = pd.DataFrame(sorted_scores_top, columns=[\"internal_item_id\", \"score\"])\n",
    "    recommendations[\"user_id\"] = user_id\n",
    "    recommendations[\"recipe_id\"] = recommendations[\"internal_item_id\"].apply(lambda x: mappings.col2itemid[x])\n",
    "    recommendations = recommendations[[\"user_id\", \"recipe_id\", \"score\"]]\n",
    "    \n",
    "    recommendations = recommendations.set_index('recipe_id').join(raw_recipes.set_index('id'))\n",
    "    recommendations.drop(['name'], axis = 1, inplace = True)\n",
    "    recommendations.drop(['contributor_id'], axis = 1, inplace = True)\n",
    "    recommendations.drop(['submitted'], axis = 1, inplace = True)\n",
    "    recommendations.drop(['user_id'], axis = 1, inplace = True)\n",
    "    recommendations.reset_index(inplace=True)\n",
    "             \n",
    "    # Convert to json \n",
    "    recommendations = recommendations.to_json(orient=\"records\")\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"recipe_id\":415097,\"score\":2.2480459213,\"minutes\":10,\"tags\":\"[\\'15-minutes-or-less\\', \\'time-to-make\\', \\'course\\', \\'preparation\\', \\'for-1-or-2\\', \\'low-protein\\', \\'beverages\\', \\'easy\\', \\'dietary\\', \\'low-sodium\\', \\'low-cholesterol\\', \\'low-calorie\\', \\'low-carb\\', \\'low-in-something\\', \\'number-of-servings\\', \\'3-steps-or-less\\']\",\"nutrition\":\"[111.8, 10.0, 41.0, 2.0, 3.0, 14.0, 3.0]\",\"n_steps\":3,\"steps\":\"[\\'stir together the hot espresso , creamer , and cinnamon in a glass measuring cup\\', \\'pour into 2 mugs\\', \\'add a scoop of ice cream to each and sprinkle with cardamom\\']\",\"description\":\"trying to stay away from the coffee shops and make my own drinks and save money!!\",\"ingredients\":\"[\\'brewed espresso\\', \\'non-dairy coffee creamer\\', \\'ground cinnamon\\', \\'vanilla ice cream\\', \\'ground cardamom\\']\",\"n_ingredients\":5},{\"recipe_id\":55457,\"score\":2.1503527164,\"minutes\":60,\"tags\":\"[\\'60-minutes-or-less\\', \\'time-to-make\\', \\'course\\', \\'cuisine\\', \\'preparation\\', \\'occasion\\', \\'north-american\\', \\'desserts\\', \\'american\\', \\'oven\\', \\'holiday-event\\', \\'cakes\\', \\'wedding\\', \\'equipment\\', \\'number-of-servings\\']\",\"nutrition\":\"[6989.2, 472.0, 2778.0, 163.0, 155.0, 934.0, 337.0]\",\"n_steps\":19,\"steps\":\"[\\'preheat oven to 325 and butter two 9 inch round cake pans , line with parchment or waxed paper , and then butter the paper\\', \\'sift flour , baking soda and salt in a bowl\\', \\'in another bowl with an electric mixer , beat the butter until light , add the sugar a little at a time and beat until light and fluffy\\', \\'beat in the eggs and vanilla\\', \\'beat in 1 \\\\/ 3 of the dry ingredients alternately with 1 \\\\/ 2 of the butter milk until combined well\\', \\'add half the remaining dry ingredients and the remaining butter milk , beat until combined well\\', \\'finally add in the remaining dry ingredients and beat until smooth\\', \\'evenly divide the batter between pans and bake for 45 minutes or until a cake tester interted comes out clean\\', \\'leave the cakes in the pans meanwhile make the syrup by mixing the juice and sugar until dissolved\\', \\'once the cake is cooked , poke holes 1 \\\\/ 2 inch apart with a toothpick and spoon the syrup over each layer\\', \\'let the layers cool completely in the pans\\', \\\\\"when the cakes are cool , heat the marmalade over moderate heat until it\\'s meltetd and let it stand for 5 minutes\\\\\", \\'place the first layer on a cake plate and carefully peel off the waxed paper spread 2 \\\\/ 3 of the marmalade over the top right to the edge\\', \\'invert the remaining layer and peel off the waxed paper\\', \\'spoon the marmalade onto the center of it , leaving a 1 1 \\\\/ 4 inch rim bare along the edges\\', \\'in another bowl prepare the frosting by whisking the heavy cream with the sugar until stiff peaks form\\', \\'add the sour cream a little at a time and whisk until spreading consistency\\', \\'spread the frosting along the sides of the cake and along the bare rim on the top , leaving the marmalde on the top exposed\\', \\'chill for 2 hours at least and stand back when you serve it !\\']\",\"description\":\"as soon as i tasted this i had to get onto email and send the recipe to all my baking friends! it has a rich and dense texture that everybody just loved!\",\"ingredients\":\"[\\'flour\\', \\'baking soda\\', \\'salt\\', \\'butter\\', \\'granulated sugar\\', \\'eggs\\', \\'vanilla\\', \\'buttermilk\\', \\'juice\\', \\'sugar\\', \\'marmalade\\', \\'heavy cream\\', \\'sour cream\\']\",\"n_ingredients\":13},{\"recipe_id\":103760,\"score\":2.1319804192,\"minutes\":10,\"tags\":\"[\\'15-minutes-or-less\\', \\'time-to-make\\', \\'course\\', \\'cuisine\\', \\'preparation\\', \\'for-1-or-2\\', \\'low-protein\\', \\'healthy\\', \\'sauces\\', \\'appetizers\\', \\'condiments-etc\\', \\'asian\\', \\'vietnamese\\', \\'easy\\', \\'low-fat\\', \\'dips\\', \\'dietary\\', \\'low-cholesterol\\', \\'low-saturated-fat\\', \\'low-calorie\\', \\'savory-sauces\\', \\'low-in-something\\', \\'number-of-servings\\', \\'3-steps-or-less\\']\",\"nutrition\":\"[275.0, 0.0, 233.0, 295.0, 13.0, 0.0, 21.0]\",\"n_steps\":4,\"steps\":\"[\\'boil water with vinegar and sugar\\', \\'allow it to cool\\', \\'combine garlic , peppers , and add mixture\\', \\'stir in the fish sauce\\']\",\"description\":\"dipping sauce posted in response to a request. source: adoptvietnam.org.\",\"ingredients\":\"[\\'water\\', \\'rice vinegar\\', \\'sugar\\', \\'fish sauce\\', \\'garlic\\', \\'fresh chili peppers\\']\",\"n_ingredients\":6}]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_recipe_id = [4065, 10123, 295797, 108524, 10045]\n",
    "get_recommendations(3, new_user_recipe_id, \"C:/Users/leaed/Documents/Techlabs/Mealwheeldata/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random recipe_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mariia has the working version\n",
    "\"\"\"\n",
    "def random_recipe_ids(n, path):\n",
    "    \"\"\"\n",
    "    n: number of random recipe_ids\n",
    "    path: Path to folder with the files. If path=\"\", files must be in the same folder as this notebook\n",
    "    Returns: n random recipe_ids\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    raw_recipes = load_data(path)\n",
    "    #random = raw_interactions.loc[raw_interactions['rating'] == 5]\n",
    "    #random = raw_recipes['id'].sample(n)\n",
    "    random = raw_recipes.sample(n,replace=True)\n",
    "    #random1 = random.to_frame()\n",
    "    return random\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#filter via tags\n",
    "    to_adrian[\"tags\"] = to_adrian[\"tags\"].apply(eval)\n",
    "    #entweder\n",
    "    x = 0\n",
    "    while x < 3:\n",
    "        not_in_list = tag not in to_adrian.iloc[x][\"tags\"]\n",
    "        if not_in_list == True:\n",
    "            to_adrian.drop([x], inplace=True, axis=0)\n",
    "        x = x + 1\n",
    "    #oder    \n",
    "    for x in range(len(to_adrian.index)):\n",
    "        not_in_list = tag not in to_adrian.iloc[x][\"tags\"]\n",
    "        if not_in_list == True:\n",
    "            to_adrian.drop([x], inplace=True, axis=0)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
